{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is added by sphinx-gallery\n",
    "# It can be customized to whatever you like\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contextuality and inductive bias in QML\n",
    "=======================================\n",
    "\n",
    "::: {.meta}\n",
    ":property=\\\"og:description\\\": Train a tailored quantum model on a\n",
    "contextuality-inspired dataset :property=\\\"og:image\\\":\n",
    "<https://pennylane.ai/qml/_images/contextuality_thumbnail.png>\n",
    ":::\n",
    "\n",
    "::: {.related}\n",
    "tutorial\\_geometric\\_qml\n",
    ":::\n",
    "\n",
    "*Author: Joseph Bowles --- Posted: 21 March 2023*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What machine learning problems are quantum computers likely to excel at?\n",
    "\n",
    "In the article *Contextuality and inductive bias in quantum machine\n",
    "learning* by Joseph Bowles, Victoria J Wright, Máté Farkas, Nathan\n",
    "Killoran and Maria Schuld, we look to contextuality for answers to this\n",
    "question.\n",
    "\n",
    "Contextuality is a nonclassical phenomenon exhibited by quantum systems,\n",
    "and it is necessary for computational advantage relative to classical\n",
    "machines. To be a little more specific, we focus on the framework of\n",
    "*generalized contextuality*, which was introduced by Robert Spekkens in\n",
    "2004. We find learning problems for which contextuality plays a key\n",
    "role, and these problems may therefore be good areas where quantum\n",
    "machine learning algorithms shine. In this demo we will:\n",
    "\n",
    "-   Describe a specific example of a contextuality-relevant problem that\n",
    "    is based on the well-known rock-paper-scissors game, and\n",
    "-   Construct and train a quantum model that is tailored to the\n",
    "    symmetries of the problem.\n",
    "\n",
    "Throughout the demo we will make use of JAX to vectorise and\n",
    "just-in-time compile certain functions, which will speed things up. For\n",
    "more information on how to combine JAX and PennyLane, see the PennyLane\n",
    "[documentation](https://docs.pennylane.ai/en/stable/introduction/interfaces/jax.html).\n",
    "\n",
    "![](../demonstrations/contextuality/socialthumbnail_large_Contextuality.png){.align-center\n",
    "width=\"50.0%\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalized contextuality\n",
    "=========================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to prepare the maximally mixed state of a single qubit,\n",
    "with $\\rho = \\frac{1}{2}\\mathbb{I}$. Although this corresponds to a\n",
    "single density matrix, there are many ways we could prepare the state.\n",
    "For example, we could mix the states $\\vert 0 \\rangle$ or\n",
    "$\\vert 1 \\rangle$ with equal probability. Alternatively, we could use\n",
    "the $X$ basis, and mix the states $\\vert + \\rangle$ or\n",
    "$\\vert - \\rangle$. Even though this may not strike us as particularly\n",
    "strange, a remarkable coincidence is in fact going on here: an\n",
    "experimentalist can perform two physically distinct procedures (namely,\n",
    "preparing $\\rho$ in the $Z$ or $X$ basis), however it is impossible to\n",
    "distinguish which procedure was performed, since they both result in the\n",
    "same density matrix and therefore give identical predictions for all\n",
    "future measurements.\n",
    "\n",
    "Such a coincidence demands an explanation. Something that one might\n",
    "expect is the following: the description of the experiment in terms of\n",
    "quantum states is not the most fundamental, and there are in fact other\n",
    "states (we'll write them as $\\lambda$), that comprise our quantum\n",
    "states. In contextuality these are called *ontic states*, although they\n",
    "also go by the name of *hidden variables*. When we prepare a state\n",
    "$\\vert 0 \\rangle$, $\\vert 1 \\rangle$, $\\vert + \\rangle$,\n",
    "$\\vert - \\rangle$, what is really going on is that we prepare a mixture\n",
    "$P_{\\vert 0 \\rangle}(\\lambda)$, $P_{\\vert 1 \\rangle}(\\lambda)$,\n",
    "$P_{\\vert + \\rangle}(\\lambda)$, $P_{\\vert - \\rangle}(\\lambda)$ over the\n",
    "true ontic states. One may imagine that the corresponding mixtures over\n",
    "the $\\lambda$ s are the same for the $Z$ and $X$ basis preparation:\n",
    "\n",
    "$$\\frac{1}{2}P_{\\vert 0 \\rangle}(\\lambda)+\\frac{1}{2}P_{\\vert 1 \\rangle}(\\lambda)=\\frac{1}{2}P_{\\vert + \\rangle}(\\lambda)+\\frac{1}{2}P_{\\vert - \\rangle}(\\lambda).$$\n",
    "\n",
    "This is a rather natural explanation of our coincidence: the two\n",
    "procedures are indistinguishable because they actually correspond to the\n",
    "same mixture over the fundamental states $\\lambda$. This sort of\n",
    "explanation is called *non-contextual*, since the two mixtures do not\n",
    "depend on the basis (that is, the context) in which the state is\n",
    "prepared. It turns out that if one tries to apply this logic to all the\n",
    "indistinguishabilities in quantum theory, one arrives at contradictions:\n",
    "it simply cannot be done. For this reason we say that quantum theory is\n",
    "a *contextual* theory.\n",
    "\n",
    "In the paper we frame generalized contextuality in the machine learning\n",
    "setting, which allows us to define what we mean by a contextual learning\n",
    "model. In a nutshell, this definition demands that if a learning model\n",
    "is non-contextual, then any indistinguishabilities in the model should\n",
    "be explained in a non-contextual way similar to the above. This results\n",
    "in constraints on the learning model, which limits their expressivity.\n",
    "Since quantum models are contextual, they can of course go beyond these\n",
    "constraints, and understanding when and how they do this may shed light\n",
    "on the non-classical features that separate quantum models from\n",
    "classical ones.\n",
    "\n",
    "Below we describe a specific learning problem that demonstrates this\n",
    "approach. As we will see, the corresponding indistinguishability relates\n",
    "to an *inductive bias* of the learning model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rock-paper-scissors game\n",
    "============================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning problem we will consider involves three players (we\\'ll\n",
    "call them players 0, 1 and 2) playing a variant of the\n",
    "rock-paper-scissors game with a referee. The game goes as follows. In\n",
    "each round, a player can choose to play either rock (R), paper (P) or\n",
    "scissors (S). Each player also has a 'special' action. For player 0 it\n",
    "is R, for player 1 it is P and for player 2 it is S. The actions of the\n",
    "players are then compared pairwise, with the following rules:\n",
    "\n",
    "-   If two players play different actions, then one player beats the\n",
    "    other following the usual rule (rock beats scissors, scissors beats\n",
    "    paper, paper beats rock).\n",
    "-   If two players play the same action, the one who plays their special\n",
    "    action beats the other. If neither plays their special action, it is\n",
    "    a draw.\n",
    "\n",
    "A referee then decides the winners and the losers of that round: the\n",
    "winners receive $\\$1$ and the losers lose $\\$1$ (we will call this their\n",
    "*payoff* for that round).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../demonstrations/contextuality/rps.png){.align-center\n",
    "width=\"50.0%\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, the more players a given player beats, the higher the\n",
    "probability that they get a positive payoff. In particular, if we denote\n",
    "the payoff of player $k$ by $y_k=\\pm1$ then\n",
    "\n",
    "$$\\mathbb{E}(y_k) = \\frac{n^k_{\\text{win}}-n^k_{\\text{lose}}}{2},$$\n",
    "\n",
    "where $n^k_{\\text{win}}$, $n^k_{\\text{lose}}$ is the number of players\n",
    "that player $k$ beats or loses to in that round. This ensures that a\n",
    "player is certain to get a positive (or negative) payoff if they beat\n",
    "(or lose) to everyone.\n",
    "\n",
    "To make this concrete, we will construct three 3x3 matrices `A01`,\n",
    "`A02`, `A12` which determine the rules for each pair of players. `A01`\n",
    "contains the expected payoff values of player 0 when playing against\n",
    "player 1. Using the rules of the game it looks as follows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../demonstrations/contextuality/rpstable.png){.align-center\n",
    "width=\"50.0%\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices `A02` and `A12` are defined similarly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "from jax import config\n",
    "config.update('jax_enable_x64', True)\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "np.random.seed(666) # seed used for random functions\n",
    "\n",
    "A01 = np.array([[1, -1, 1], [1, -1, -1], [-1, 1, 0]])  # rules for player 0 vs player 1\n",
    "A02 = np.array([[1, -1, 1], [1, 0, -1], [-1, 1, -1]])\n",
    "A12 = np.array([[0, -1, 1], [1, 1, -1], [-1, 1, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define the matrices `A10`, `A20`, `A21`. Since switching the\n",
    "players corresponds to taking the transpose matrix and a positive payoff\n",
    "for one player implies a negative for the other, these matrices are\n",
    "given by the negative of the transposed matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "A10 = -A01.T  # rules for player 1 vs player 0\n",
    "A20 = -A02.T\n",
    "A21 = -A12.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above game is an example of a *zero-sum game*: if player 1\n",
    "beats player 2 then necessarily player 2 loses to player 1. This implies\n",
    "$\\sum_k n^k_{\\text{wins}}=\\sum_kn^k_{\\text{lose}}$ and so in every round\n",
    "we have\n",
    "\n",
    "$$\\mathbb{E}(y_1)+\\mathbb{E}(y_2)+\\mathbb{E}(y_3)=0.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the dataset \\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\--\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct a dataset based on the above game. Our data points\n",
    "correspond to probability distributions over possible actions: in the\n",
    "zero-sum game literature these are called *strategies*. For example, a\n",
    "strategy for player k is a vector\n",
    "\n",
    "$$x_k=(P(a_k=R), P(a_k=P), P(a_k=S))$$\n",
    "\n",
    "where $a_k$ denotes player $k$'s action. We collect these into a\n",
    "strategy matrix X\n",
    "\n",
    "$$\\begin{aligned}\n",
    "X = \\begin{pmatrix}\n",
    "    P(a_0=R) & P(a_0=P) & P(a_0=S) \\\\\n",
    "    P(a_1=R) & P(a_1=P) & P(a_1=S) \\\\\n",
    "    P(a_2=R) & P(a_2=P) & P(a_2=S) .\n",
    "    \\end{pmatrix}\n",
    "\\end{aligned}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function to generate a set of strategy matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_strategy_matrices(N):\n",
    "    \"\"\"\n",
    "    Generates N strategy matrices, normalised by row\n",
    "    \"\"\"\n",
    "    X = np.random.rand(N, 3, 3)\n",
    "    for i in range(N):\n",
    "        norm = np.array(X[i].sum(axis=1))\n",
    "        for k in range(3):\n",
    "            X[i, k, :] = X[i, k, :] / norm[k]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels in our dataset correspond to payoff values $y_k$ of the three\n",
    "players. Following the rules of probability we find that if the players\n",
    "use strategies $x_0, x_1, x_2$ the expected values of\n",
    "$n_{\\text{wins}}^k - n_{\\text{lose}}^k$ are given by\n",
    "\n",
    "$$\\mathbb{E}[n_{\\text{wins}}^0 - n_{\\text{lose}}^0]  = x_0 \\cdot A_{01}\\cdot x_1^T+x_0 \\cdot A_{02}\\cdot x_2^T$$\n",
    "\n",
    "$$\\mathbb{E}[n_{\\text{wins}}^1 - n_{\\text{lose}}^1] = x_1 \\cdot A_{10}\\cdot x_0^T+x_1 \\cdot A_{12}\\cdot x_2^T$$\n",
    "\n",
    "$$\\mathbb{E}[n_{\\text{wins}}^2 - n_{\\text{lose}}^2] = x_2 \\cdot A_{20}\\cdot x_0^T+x_2 \\cdot A_{21}\\cdot x_1^T$$\n",
    "\n",
    "Since we have seen that\n",
    "$\\mathbb{E}(y_k) = \\frac{n^k_{\\text{win}}-n^k_{\\text{lose}}}{2}$ it\n",
    "follows that the probability for player $k$ to receive a positive payoff\n",
    "given strategies $X$ is\n",
    "\n",
    "$$P(y_k=+1\\vert X) = \\frac{\\mathbb{E}(y_k\\vert X)+1}{2} =  \\frac{(\\mathbb{E}[n_{\\text{wins}}^k - n_{\\text{lose}}^k])/2+1}{2}$$\n",
    "\n",
    "Putting all this together we can write some code to generate the labels\n",
    "for our data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31535055 0.38006941 0.30458004]\n",
      " [0.43017127 0.56232101 0.00750771]\n",
      " [0.73549054 0.08680468 0.17770478]]\n",
      "[-1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "def payoff_probs(X):\n",
    "    \"\"\"\n",
    "    get the payoff probabilities for each player given a strategy matrix X\n",
    "    \"\"\"\n",
    "    n0 = X[0] @ A01 @ X[1] + X[0] @ A02 @ X[2]  # n0 = <n0_wins - n0_lose>\n",
    "    n1 = X[1] @ A10 @ X[0] + X[1] @ A12 @ X[2]\n",
    "    n2 = X[2] @ A20 @ X[0] + X[2] @ A21 @ X[1]\n",
    "    probs = (jnp.array([n0, n1, n2]) / 2 + 1) / 2\n",
    "    return probs\n",
    "\n",
    "\n",
    "# JAX vectorisation\n",
    "vpayoff_probs = jax.vmap(payoff_probs)\n",
    "\n",
    "\n",
    "def generate_data(N):\n",
    "    X = get_strategy_matrices(N)  # strategies\n",
    "    P = vpayoff_probs(X)  # payoff probabilities\n",
    "    r = np.random.rand(*P.shape)\n",
    "    Y = np.where(P > r, 1, -1)  # sampled payoffs for data labels\n",
    "    return X, Y, P\n",
    "\n",
    "\n",
    "X, Y, P = generate_data(2000)\n",
    "\n",
    "print(X[0])  # the first strategy matrix in our dataset\n",
    "print(Y[0])  # the corresponding sampled payoff values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since strategies are probabilistic mixtures of actions, our\n",
    "data labels satisfy a zero-sum condition\n",
    "\n",
    "$$\\mathbb{E}(y_1\\vert X_i)+\\mathbb{E}(y_2\\vert X_i)+\\mathbb{E}(y_3\\vert X_i)=0.$$\n",
    "\n",
    "We can verify this using the payoff probability matrix `P` that we used\n",
    "to sample the labels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.00000000e+00,  1.11022302e-16,  0.00000000e+00,  1.11022302e-16,\n",
       "        0.00000000e+00, -2.22044605e-16,  0.00000000e+00, -1.11022302e-16,\n",
       "       -2.22044605e-16,  0.00000000e+00], dtype=float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expvals = 2 * P - 1  # convert probs to expvals\n",
    "expvals[:10].sum(axis=1)  # check first 10 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning problem\n",
    "====================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are given a data set $\\{X_i,\\vec{y}_i\\}$ consisting of\n",
    "strategy matrices and payoff values, however we don't know what the\n",
    "underlying game is (that is, we don't know the players were playing the\n",
    "rock, paper scissors game described above). We do have one piece of\n",
    "information though: we know the game is zero-sum so that the data\n",
    "generation process satisfies\n",
    "\n",
    "$$\\mathbb{E}(y_0\\vert X_i)+\\mathbb{E}(y_1\\vert X_i)+\\mathbb{E}(y_2\\vert X_i)=0.$$\n",
    "\n",
    "Can we learn the rock, paper scissors game from this data? More\n",
    "precisely, if we are given an unseen strategy matrix $X_{\\text{test}}$\n",
    "our task is to sample from the three distributions\n",
    "\n",
    "$$P(y_0\\vert X_{\\text{test}}), P(y_1\\vert X_{\\text{test}}), P(y_2\\vert X_{\\text{test}}).$$\n",
    "\n",
    "Note we are not asking to sample from the joint distribution\n",
    "$P(\\vec{y}\\vert X_{\\text{test}})$ but the three marginal distributions\n",
    "only. This can be seen as an instance of multi-task learning, where a\n",
    "single task corresponds to sampling the payoff for one of the three\n",
    "players.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building inductive bias into a quantum model\n",
    "============================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we describe a simple three qubit model to tackle this problem.\n",
    "Since we know that the data satisfies the zero-sum condition, we aim to\n",
    "create a quantum model that encodes this knowledge. That is, like the\n",
    "data we want our model to satisfy\n",
    "\n",
    "$$\\mathbb{E}(y_0\\vert X_i)+\\mathbb{E}(y_1\\vert X_i)+\\mathbb{E}(y_2\\vert X_i)=0.$$\n",
    "\n",
    "In machine learning, this is called encoding an *inductive bias* into\n",
    "the model, and considerations like this are often crucial for good\n",
    "generalisation performance.\n",
    "\n",
    "::: {.note}\n",
    "::: {.title}\n",
    "Note\n",
    ":::\n",
    "\n",
    "Since the above holds for all $X_i$, it implies an indistinguishability\n",
    "of the model: if we look at one of the labels at random, we are equally\n",
    "likely to see a positive or negative payoff regardless of $X_i$, and so\n",
    "the $X_i$ are indistinguishable with respect to this observation. This\n",
    "implies a corresponding constraint on non-contextual learning models,\n",
    "which limits their expressivity and may therefore hinder their\n",
    "performance: see the paper for more details on how this looks in\n",
    "practice. Luckily for us quantum theory is a contextual theory, so these\n",
    "limitations don't apply to our model!\n",
    ":::\n",
    "\n",
    "The quantum model we consider has the following structure:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../demonstrations/contextuality/model.png){.align-center\n",
    "width=\"50.0%\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters $\\theta$ and $\\alpha$ are trainable parameters of the\n",
    "model, and we will use the three $Z$ measurements at the end of the\n",
    "circuit to sample the three labels. Therefore, if we write the entire\n",
    "circuit as $\\vert \\psi(\\alpha,\\theta,X)\\rangle$ the zero sum condition\n",
    "will be satisfied if\n",
    "\n",
    "$$\\langle \\psi(\\alpha,\\theta,X) \\vert (Z_0+Z_1+Z_2) \\vert \\psi(\\alpha,\\theta,X) \\rangle = 0.$$\n",
    "\n",
    "Let's see how we can create a model class that satisfies this. For\n",
    "precise details on the structure of the model, check out Figure 6 in the\n",
    "paper. We'll first look at the parameterised unitary $V_{\\alpha}$, that\n",
    "we call the *input preparation unitary*. This prepares a state\n",
    "$V_\\alpha\\vert 0 \\rangle$ such that\n",
    "\n",
    "$$\\langle 0 \\vert V^\\dagger_\\alpha (Z_0+Z_1+Z_2) V_\\alpha\\vert 0 \\rangle = 0.$$\n",
    "\n",
    "An example of such a circuit is the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def input_prep(alpha):\n",
    "    # This ensures the prepared state has <Z_0+Z_1+Z_2>=0\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.Hadamard(wires=2)\n",
    "    qml.RY(alpha[0], wires=0)\n",
    "    qml.RY(alpha[0] + np.pi, wires=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second unitary is a *bias invariant layer*: it preserves the value\n",
    "of $\\langle Z_0+Z_1+Z_2 \\rangle$ for all input states into the layer. To\n",
    "achieve this, the generators of the unitaries in this layer must commute\n",
    "with the operator $Z_0+Z_1+Z_2$. For example the operator\n",
    "$X\\otimes X + Y\\otimes Y + Z\\otimes Z$ (on any pair of qubits) commutes\n",
    "with $Z_0+Z_1+Z_2$ and so a valid parameterised gate could be\n",
    "\n",
    "$$e^{i\\theta(X\\otimes X\\otimes\\mathbb{I} + Y\\otimes Y\\otimes\\mathbb{I} + Z\\otimes Z\\otimes\\mathbb{I})}.$$\n",
    "\n",
    "This kind of reasoning is an example of geometric quantum machine\n",
    "learning (check out and or our own\n",
    "[demo](https://pennylane.ai/qml/demos/tutorial_geometric_qml.html) for\n",
    "an awesome introduction to the subject). Below we construct the bias\n",
    "invariant layer: note that all the generators commute with\n",
    "$Z_0+Z_1+Z_2$. The variables `blocks` and `layers` are model\n",
    "hyperparameters that we will fix as `blocks=1` and `layers=2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "blocks = 1\n",
    "layers = 2\n",
    "\n",
    "\n",
    "def swap_rot(weights, wires):\n",
    "    \"\"\"\n",
    "    bias-invariant unitary with swap matrix as generator\n",
    "    \"\"\"\n",
    "    qml.PauliRot(weights, \"XX\", wires=wires)\n",
    "    qml.PauliRot(weights, \"YY\", wires=wires)\n",
    "    qml.PauliRot(weights, \"ZZ\", wires=wires)\n",
    "\n",
    "\n",
    "def param_unitary(weights):\n",
    "    \"\"\"\n",
    "    A bias-invariant unitary (U in the paper)\n",
    "    \"\"\"\n",
    "    for b in range(blocks):\n",
    "        for q in range(3):\n",
    "            qml.RZ(weights[b, q], wires=q)\n",
    "        qml.PauliRot(weights[b, 3], \"ZZ\", wires=[0, 1])\n",
    "        qml.PauliRot(weights[b, 4], \"ZZ\", wires=[0, 2])\n",
    "        qml.PauliRot(weights[b, 5], \"ZZ\", wires=[1, 2])\n",
    "        swap_rot(weights[b, 6], wires=[0, 1])\n",
    "        swap_rot(weights[b, 7], wires=[1, 2])\n",
    "        swap_rot(weights[b, 8], wires=[0, 2])\n",
    "\n",
    "\n",
    "def data_encoding(x):\n",
    "    \"\"\"\n",
    "    S_x^1 in paper\n",
    "    \"\"\"\n",
    "    for q in range(3):\n",
    "        qml.RZ(x[q], wires=q)\n",
    "\n",
    "\n",
    "def data_encoding_pairs(x):\n",
    "    \"\"\"\n",
    "    S_x^2 in paper\n",
    "    \"\"\"\n",
    "    qml.PauliRot(x[0] * x[1], \"ZZ\", wires=[0, 1])\n",
    "    qml.PauliRot(x[1] * x[2], \"ZZ\", wires=[1, 2])\n",
    "    qml.PauliRot(x[0] * x[2], \"ZZ\", wires=[0, 2])\n",
    "\n",
    "\n",
    "def bias_inv_layer(weights, x):\n",
    "    \"\"\"\n",
    "    The full bias invariant layer.\n",
    "    \"\"\"\n",
    "    # data preprocessing\n",
    "    x1 = jnp.array([x[0, 0], x[1, 1], x[2, 2]])\n",
    "    x2 = jnp.array(([x[0, 1] - x[0, 2], x[1, 2] - x[1, 0], x[2, 0] - x[2, 1]]))\n",
    "    for l in range(0, 2 * layers, 2):\n",
    "        param_unitary(weights[l])\n",
    "        data_encoding(x1)\n",
    "        param_unitary(weights[l + 1])\n",
    "        data_encoding_pairs(x2)\n",
    "    param_unitary(weights[2 * layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our `input_prep` and `bias_inv_layer` functions we can now define\n",
    "our quantum model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum simulator/QPU\n",
    "#dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "#dev = qml.device(\"default.qubit\", wires=4)\n",
    "#n_shots=1000\n",
    "n_shots=2000\n",
    "n_qubits=3\n",
    "#dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "#dev = qml.device('braket.aws.qubit', device_arn='arn:aws:braket:eu-west-2::device/qpu/oqc/Lucy', wires=n_qubits, shots=n_shots)\n",
    "dev = qml.device('braket.aws.qubit', device_arn='arn:aws:braket:::device/quantum-simulator/amazon/sv1', wires=n_qubits, shots=n_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@qml.qnode(dev)\n",
    "def model(weights, x):\n",
    "    input_prep(weights[2 * layers + 1, 0])  # alpha is stored in the weights array\n",
    "    bias_inv_layer(weights, x)\n",
    "    return [qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2))]\n",
    "\n",
    "\n",
    "# jax vectorisation, we vectorise over the data input (the second argument)\n",
    "vmodel = jax.vmap(model, (None, 0))\n",
    "vmodel = jax.jit(vmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate the effect of the encoded inductive bias, we will compare\n",
    "this model to a generic model with the same data encoding and similar\n",
    "number of parameters (46 vs 45 parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generic_layer(weights, x):\n",
    "    # data preprocessing\n",
    "    x1 = jnp.array([x[0, 0], x[1, 1], x[2, 2]])\n",
    "    x2 = jnp.array(([x[0, 1] - x[0, 2], x[1, 2] - x[1, 0], x[2, 0] - x[2, 1]]))\n",
    "    for l in range(0, 2 * layers, 2):\n",
    "        qml.StronglyEntanglingLayers(weights[l], wires=range(3))\n",
    "        data_encoding(x1)\n",
    "        qml.StronglyEntanglingLayers(weights[l + 1], wires=range(3))\n",
    "        data_encoding_pairs(x2)\n",
    "    qml.StronglyEntanglingLayers(weights[2 * layers], wires=range(3))\n",
    "\n",
    "\n",
    "#dev = qml.device(\"default.qubit\", wires=3)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def generic_model(weights, x):\n",
    "    generic_layer(weights, x)\n",
    "    return [qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2))]\n",
    "\n",
    "\n",
    "vmodel_generic = jax.vmap(generic_model, (None, 0))\n",
    "vmodel_generic = jax.jit(vmodel_generic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: Since we are using JAX it is important that our `model` and\n",
    "`generic model` functions are functionally pure (read more\n",
    "[here](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html)).\n",
    "This means we cannot change the values of `blocks` or `layers` from\n",
    "hereon since these values have been cached for JIT compilation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluation\n",
    "=======================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model we will minimise the negative log likelihood of the\n",
    "labels given the data\n",
    "\n",
    "$$\\mathcal{L} = -\\frac{1}{3\\vert N \\vert}\\sum_{(X_i,\\vec{y}_i)} \\log(\\mathcal{P}_0(y_i^{(0)}\\vert X_i))+\\log(\\mathcal{P}_1(y_i^{(1)}\\vert X_i))+\\log(\\mathcal{P}_2(y_i^{(2)}\\vert X_i))$$\n",
    "\n",
    "Here $\\mathcal{P}_k$ is the probability distribution of the $k$ label\n",
    "from the model, $y_i^{(k)}$ is the kth element of the payoff vector\n",
    "$\\vec{y}_i$ in the dataset, and $N$ is the size of the training dataset.\n",
    "We remark that training the negative log likelihood is in some sense\n",
    "cheating, since for large quantum circuits we don't know how to estimate\n",
    "it efficiently. As generative modeling in QML progresses, we can hope\n",
    "however that scalable methods that approximate this type of training may\n",
    "appear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def likelihood(weights, X, Y, model):\n",
    "    \"\"\"\n",
    "    The cost function. Returns the negative log likelihood\n",
    "    \"\"\"\n",
    "    expvals = jnp.array(model(weights, X)).T\n",
    "    probs = (1 + Y * expvals) / 2  # get the relevant probabilites\n",
    "    probs = jnp.log(probs)\n",
    "    llh = jnp.sum(probs) / len(X) / 3\n",
    "    return -llh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation we will use the average KL divergence between the true\n",
    "data distribution and the model distribution\n",
    "\n",
    "$$\\mathbb{E}_{P^\\text{data}(X)} \\left[\\frac{1}{3}\\sum_{k=1}^{3} D_{\\text{KL}}(P^\\text{data}_k(y\\vert X)\\vert\\vert \\mathcal{P}_k(y\\vert X)) \\right].$$\n",
    "\n",
    "To estimate this we sample a test set of strategies, calculate their\n",
    "payoff probabilities, and estimate the above expectation via the sample\n",
    "mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "N_test = 10000\n",
    "X_test = get_strategy_matrices(N_test)\n",
    "\n",
    "probs_test = np.zeros([N_test, 3, 2])\n",
    "probs_test[:, :, 0] = vpayoff_probs(X_test)  # the true probabilities for the test set\n",
    "probs_test[:, :, 1] = 1 - probs_test[:, :, 0]\n",
    "probs_test = jnp.array(probs_test)\n",
    "\n",
    "\n",
    "def kl_div(p, q):\n",
    "    \"\"\"\n",
    "    Get the KL divergence between two probability distribtuions\n",
    "    \"\"\"\n",
    "    p = jnp.vstack([p, jnp.ones(len(p)) * 10 ** (-8)])  # lower cutoff of prob values of 10e-8\n",
    "    p = jnp.max(p, axis=0)\n",
    "    return jnp.sum(q * jnp.log(q / p))  # forward kl div\n",
    "\n",
    "\n",
    "def kl_marginals(probs, probs_test):\n",
    "    \"\"\"\n",
    "    get the mean KL divergence of the three marginal distributions\n",
    "    (the square brackets above)\n",
    "    \"\"\"\n",
    "    kl = 0\n",
    "    for t in range(3):\n",
    "        kl = kl + kl_div(probs[t, :], probs_test[t, :])\n",
    "    return kl / 3\n",
    "\n",
    "\n",
    "# vectorise the kl_marginals function. Makes estimating the average KL diverence of a model faster.\n",
    "vkl_marginals = jax.vmap(kl_marginals, (0, 0))\n",
    "\n",
    "\n",
    "def get_av_test_kl(model, weights, probs_test, X_test):\n",
    "    \"\"\"\n",
    "    returns the average KL divergence for a test set X_test.\n",
    "    \"\"\"\n",
    "    N_test = len(X_test)\n",
    "    probs = np.zeros(probs_test.shape)\n",
    "    expvals = jnp.array(model(weights, X_test)).T\n",
    "    for t in range(3):\n",
    "        probs[:, t, 0] = (1 + expvals[:, t]) / 2\n",
    "        probs[:, t, 1] = (1 - expvals[:, t]) / 2\n",
    "    return np.sum(vkl_marginals(probs, probs_test)) / N_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimise the model we make use of the JAX optimization library optax.\n",
    "We will use the adam gradient descent optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def optimise_model(model, nstep, lr, weights):\n",
    "    plot = [[], [], []]\n",
    "    optimizer = optax.adam(lr)\n",
    "    opt_state = optimizer.init(weights)\n",
    "    steps = tqdm(range(nstep))\n",
    "    for step in steps:\n",
    "        #         use optax to update parameters\n",
    "        llh, grads = jax.value_and_grad(likelihood)(weights, X, Y, model)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state, weights)\n",
    "        weights = optax.apply_updates(weights, updates)\n",
    "\n",
    "        kl = get_av_test_kl(model, weights, probs_test, X_test)\n",
    "        steps.set_description(\n",
    "            \"Current divergence: %s\" % str(kl) + \" :::: \" + \"Current likelihood: %s\" % str(llh)\n",
    "        )\n",
    "        plot[0].append(step)\n",
    "        plot[1].append(float(llh))\n",
    "        plot[2].append(float(kl))\n",
    "    return weights, llh, kl, plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to generate a data set and optimize our models!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "N = 2000  # number of data points\n",
    "X, Y, P = generate_data(N)\n",
    "\n",
    "nstep = 2000  # number of optimisation steps\n",
    "\n",
    "lr = 0.001  # initial learning rate\n",
    "weights_model = np.random.rand(2 * layers + 2, blocks, 9) * 2 * np.pi\n",
    "weights_generic = np.random.rand(2 * layers + 1, blocks, 3, 3) * 2 * np.pi\n",
    "\n",
    "# optimise the structured model\n",
    "weights_model, llh, kl, plot_model = optimise_model(vmodel, nstep, lr, weights_model)\n",
    "# optimise the generic model\n",
    "weights_generic, llh, kl, plot_genereic = optimise_model(vmodel_generic, nstep, lr, weights_generic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the average KL divergence and the negative log likelihood for\n",
    "both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('pennylane.drawer.plot')\n",
    "\n",
    "# subplots\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(8, 10))\n",
    "fig.tight_layout(pad=10.0)\n",
    "\n",
    "# KL divergence\n",
    "ax1.plot(plot_model[0], plot_model[2], label=\"biased model\")\n",
    "ax1.plot(plot_genereic[0], plot_genereic[2], label=\"generic model\")\n",
    "\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_ylabel(\"KL divergence (test)\")\n",
    "ax1.set_xlabel(\"training step\")\n",
    "ax1.legend()\n",
    "\n",
    "# negative log likelihood\n",
    "ax2.plot(plot_model[0], plot_model[1])\n",
    "ax2.plot(plot_genereic[0], plot_genereic[1])\n",
    "\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_ylabel(\"Negative log likelihood (train)\")\n",
    "ax2.set_xlabel(\"training step\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model that encodes the inductive bias achieves both a\n",
    "lower training error and generalisation error, as can be expected.\n",
    "Incorporating knowledge about the data into the model design is\n",
    "generally a very good idea!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "==========\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we have constructed a dataset whose structure is connected\n",
    "to generalized contextuality, and have shown how to encode this\n",
    "structure as an inductive bias of a quantum model class. As is often the\n",
    "case, we saw that this approach outperforms a generic model class that\n",
    "does not take this knowledge into account. As a general rule,\n",
    "considerations like this should be at the front of one\\'s mind when\n",
    "building a quantum model for a specific task.\n",
    "\n",
    "That is all for this demo. In our paper[^1], it is also shown how models\n",
    "of this kind can perform better than classical surrogate models[^2] at\n",
    "this specific task, which further strengthens the claim that the\n",
    "inductive bias of the quantum model is useful. For more information and\n",
    "to read more about the link between contextuality and QML, check out the\n",
    "full paper.\n",
    "\n",
    "References\n",
    "==========\n",
    "\n",
    "About the author\n",
    "================\n",
    "\n",
    "[^1]: J. Bowles, V. J. Wright, M. Farkas, N. Killoran, M. Schuld\n",
    "    \\\"Contextuality and inductive bias in quantum machine learning.\\\"\n",
    "    [arXiv:2302.01365](https://arxiv.org/abs/2302.01365), 2023.\n",
    "\n",
    "[^2]: F. J. Schreiber, J. Eiser, J. J. Meyer \\\"Classical surrogates for\n",
    "    quantum learning models.\\\"\n",
    "    [arXiv:2206.11740](https://arxiv.org/abs/2206.11740), 2022.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
